{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we go over the basics of web scraping, covering *some* special cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/joram/anaconda3/lib/python3.7/site-packages (4.8.2)\n",
      "Requirement already satisfied: requests in /home/joram/anaconda3/lib/python3.7/site-packages (2.22.0)\n",
      "Requirement already satisfied: lxml in /home/joram/anaconda3/lib/python3.7/site-packages (4.5.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /home/joram/anaconda3/lib/python3.7/site-packages (from beautifulsoup4) (1.9.5)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/joram/anaconda3/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/joram/anaconda3/lib/python3.7/site-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/joram/anaconda3/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/joram/anaconda3/lib/python3.7/site-packages (from requests) (2019.11.28)\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/joram/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 requests lxml # it is do-able without lxml!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why scraping\n",
    "Some websites have information of high value, a good example of this is https://www.example.org/ !\n",
    "It would be amazing if we can periodically scrape the data from this page to be notified if anything changes.\n",
    "\n",
    "Here we have a picture of the website.\n",
    "\n",
    "![example-img](../src/basic-scraping-example-img.png)\n",
    "\n",
    "What does a website consist of on the client side?\n",
    "\n",
    "![example-html](../src/basic-scraping-example-html.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining a webpage on python using the `requests` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.example.org/'\n",
    "page = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html>\\n<html>\\n<head>\\n    <title>Example Domain</title>\\n\\n    <meta charset=\"utf-8\" />\\n    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\\n    <style type=\"text/css\">\\n    body {\\n        background-color: #f0f0f2;\\n        margin: 0;\\n        padding: 0;\\n        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\\n        \\n    }\\n    div {\\n        width: 600px;\\n        margin: 5em auto;\\n        padding: 2em;\\n        background-color: #fdfdff;\\n        border-radius: 0.5em;\\n        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\\n    }\\n    a:link, a:visited {\\n        color: #38488f;\\n        text-decoration: none;\\n    }\\n    @media (max-width: 700px) {\\n        div {\\n            margin: 0 auto;\\n            width: auto;\\n        }\\n    }\\n    </style>    \\n</head>\\n\\n<body>\\n<div>\\n    <h1>Example Domain</h1>\\n    <p>This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.</p>\\n    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\\n</div>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where BeautifulSoup comes in\n",
    "It's not intuitively possible to query specific parts of a web page using only the `requests` library.\n",
    "\n",
    "Say we want to look at the heading of the document `h1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'str' object has no attribute 'h1'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    page.h1\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in an error, since the `requests.get(url).text` call returns a string object.\n",
    "\n",
    "####  In a one liner: The library **BeautifulSoup** parses *html text* into a *parsed tree* that can be used to extract data.\n",
    "\n",
    "Think of the parsed tree as a python dictionary, for example: `example_dict = {'company': 'Cape AI', 'fun factor': 'over 9000'}`\n",
    "\n",
    "Where we can then access the fields of the dictionary: `example_dict['company']` returns `'Cape AI'`\n",
    "\n",
    "Commonly, the parsed tree object is called soup, since it is a combination of a bunch of stuff and at the end you're not really sure about everything you added anymore.\n",
    "\n",
    "`soup = BS(page, parser)`\n",
    "\n",
    "Lets create a soup object of the text page of https://www.example.org/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = BS(page, 'lxml') # here you can also use 'html.parser' instead of 'lxml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily access the heading of the page using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>Example Domain</h1>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the main paragraph using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "    domain in literature without prior coordination or asking for permission.</p>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing it also looks much more user friendly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title>Example Domain</title>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-type\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
       "<style type=\"text/css\">\n",
       "    body {\n",
       "        background-color: #f0f0f2;\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "        \n",
       "    }\n",
       "    div {\n",
       "        width: 600px;\n",
       "        margin: 5em auto;\n",
       "        padding: 2em;\n",
       "        background-color: #fdfdff;\n",
       "        border-radius: 0.5em;\n",
       "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
       "    }\n",
       "    a:link, a:visited {\n",
       "        color: #38488f;\n",
       "        text-decoration: none;\n",
       "    }\n",
       "    @media (max-width: 700px) {\n",
       "        div {\n",
       "            margin: 0 auto;\n",
       "            width: auto;\n",
       "        }\n",
       "    }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<h1>Example Domain</h1>\n",
       "<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "    domain in literature without prior coordination or asking for permission.</p>\n",
       "<p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that there could be many instances of all elements/tags (h1, div, etc). Using `soup.h1` will always return the first instance.\n",
    "`soup.h1` is equivalent to using `soup.find('h1')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested elements\n",
    "Elements are generally nested in html, especially inside `div`'s, as web pages are generally split up into a large amount of divisions. These can be accessed by tracing the nesting to the element you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>Example Domain</h1>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html.body.div.h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more complicated task/website\n",
    "\n",
    "Our company website https://cape-ai.com/ is quite a bit more complicated than https://www.example.org/. \n",
    "\n",
    "Let's see what happens when we try to scrape the `h1` element of this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://cape-ai.com/'\n",
    "page = requests.get(url).text\n",
    "soup = BS(page, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"display-3 font-weight-bold text-dark\" id=\"welcomeHeadingSource\">\n",
      " <span style=\"background: rgba(250, 250, 250, 0.4)\">\n",
      "  Artificial intelligence to\n",
      " </span>\n",
      " <br/>\n",
      " <span class=\"text-white bg-primary\" data-options='{\"strings\": [\"Stop poaching\", \"Create township jobs\", \"Understand customers\", \"Improve healthcare\", \"Fight climate change\"]}' data-toggle=\"typed\">\n",
      " </span>\n",
      "</h1>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h1 = soup.h1\n",
    "print(h1.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get\n",
    "You can use `h1.get('attribute name')` to get the values of the attributes inside an element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['display-3', 'font-weight-bold', 'text-dark']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.get('class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find_all\n",
    "As mentioned before, elements can have multiple instances. Here we see two `span` elements inside the `h1` element. Using `h1.span` returns only the first instance. What if we want a list of the varying strings in the second span element?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span style=\"background: rgba(250, 250, 250, 0.4)\">Artificial intelligence to</span>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.span\n",
    "\n",
    "# same as soup.h1.span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `h1.find_all('span')`, we can find all instances of the `span` element inside `h1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span style=\"background: rgba(250, 250, 250, 0.4)\">Artificial intelligence to</span>,\n",
       " <span class=\"text-white bg-primary\" data-options='{\"strings\": [\"Stop poaching\", \"Create township jobs\", \"Understand customers\", \"Improve healthcare\", \"Fight climate change\"]}' data-toggle=\"typed\"></span>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = h1.find_all('span')\n",
    "spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span style=\"background: rgba(250, 250, 250, 0.4)\">Artificial intelligence to</span>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"text-white bg-primary\" data-options='{\"strings\": [\"Stop poaching\", \"Create township jobs\", \"Understand customers\", \"Improve healthcare\", \"Fight climate change\"]}' data-toggle=\"typed\"></span>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"strings\": [\"Stop poaching\", \"Create township jobs\", \"Understand customers\", \"Improve healthcare\", \"Fight climate change\"]}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans[1].get('data-options')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary update sequence element #0 has length 1; 2 is required\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dict(spans[1].get('data-options'))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'strings': ['Stop poaching',\n",
       "  'Create township jobs',\n",
       "  'Understand customers',\n",
       "  'Improve healthcare',\n",
       "  'Fight climate change']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(h1.find_all('span')[1].get('data-options'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stop poaching',\n",
       " 'Create township jobs',\n",
       " 'Understand customers',\n",
       " 'Improve healthcare',\n",
       " 'Fight climate change']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_fields = ast.literal_eval(h1.find_all('span')[1].get('data-options'))['strings']\n",
    "text_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortcut!\n",
    "Using `find_all` with the `attrs` argument, we can hone in one the specific element we want based on one of its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"text-white bg-primary\" data-options='{\"strings\": [\"Stop poaching\", \"Create township jobs\", \"Understand customers\", \"Improve healthcare\", \"Fight climate change\"]}' data-toggle=\"typed\"></span>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_span = soup.find_all('span', attrs={'data-toggle':'typed'})\n",
    "specific_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stop poaching',\n",
       " 'Create township jobs',\n",
       " 'Understand customers',\n",
       " 'Improve healthcare',\n",
       " 'Fight climate change']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_fields = ast.literal_eval(specific_span[0].get('data-options'))['strings']\n",
    "text_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That covers basic scraping! On to bigger things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
